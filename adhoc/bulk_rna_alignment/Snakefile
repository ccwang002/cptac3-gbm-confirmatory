import csv
from dataclasses import dataclass
import logging
from pathlib import Path
import string
from textwrap import dedent
from typing import Dict

_logger = logging.getLogger(__name__)

# List of sample names to run the pipeline
SAMPLE_TABLE_PTH = config['sample_table']
# The mapping of sample name to local file locations
FILE_MAP_PTH = config['file_map']
STAR_INDEX_FOLDER = config['star_index']  # Path to STAR index
WORKFLOW_ROOT = config['workflow_root']  # Path to this repository


@dataclass
class SampleInfo:
    """Class to keep track of the sample info."""
    unique_run_id: str
    preferred_sample_name: str
    case_id: str
    r1_fq_uuid: str
    r2_fq_uuid: str
    r1_fq_pth: Path
    r2_fq_pth: Path


# Read file map
FILE_MAP: Dict[str, Path] = {}
with open(FILE_MAP_PTH) as f:
   reader = csv.DictReader(f, dialect='excel-tab')
   for row in reader:
       FILE_MAP[row['UUID']] = Path(row['data_path'])


# Read all sample info
SAMPLE_INFO: Dict[str, SampleInfo] = {}
with open(SAMPLE_TABLE_PTH) as f:
    reader = csv.DictReader(f, dialect='excel-tab')
    for row in reader:
        run_id = row['unique_run_id']
        sample_name = row['preferred_sample_name']
        case_id = row['case_id']
        r1_fq_uuid = row['rna_raw__sample__R1__UUID']
        r2_fq_uuid = row['rna_raw__sample__R2__UUID']
        r1_fq_pth = FILE_MAP[r1_fq_uuid]
        r2_fq_pth = FILE_MAP[r2_fq_uuid]
        assert r1_fq_pth.exists()
        assert r2_fq_pth.exists()
        SAMPLE_INFO[sample_name] = SampleInfo(
            unique_run_id=run_id,
            preferred_sample_name=sample_name,
            case_id=case_id,
            r1_fq_uuid=r1_fq_uuid,
            r2_fq_uuid=r2_fq_uuid,
            r1_fq_pth=r1_fq_pth,
            r2_fq_pth=r2_fq_pth,
        )

SAMPLES = list(SAMPLE_INFO.keys())


class PartialFormatter(string.Formatter):
    """A partial string formatter.

    Example:

        >>> fmt = PartialFormatter()
        >>> fmt.format('Sale on {date} is {num_box}', date='2019-08-07')
        'Sale on 2019-08-07 is {num_box}'

    """
    def get_value(self, key, args, kwargs):
        try:
            val = super().get_value(key, args, kwargs)
        except (KeyError, IndexError):
            val = f'{{{key}}}'
        return val

_partial_fmt = PartialFormatter()


def find_sample_fastqs(wildcards):
    """Find the FASTQ file paths of a given sample."""
    sample_info = SAMPLE_INFO[wildcards.sample]
    return {
        'r1_fq': str(sample_info.r1_fq_pth),
        'r2_fq': str(sample_info.r2_fq_pth),
    }


def create_rg_line(wildcards, input):
    fq_name = Path(input.r1_fq).name
    m = re.search(r'_R[12]_\d+\.fastq\.gz$', fq_name)
    rg = fq_name[:m.start()]
    return f"ID:{rg} SM:{wildcards.sample}"


rule star_align:
    """STAR align one sample."""
    output:
        unsorted_bam=temporary('star/{sample}/Aligned.out.bam'),
        # samtools sort BAM faster
        # sorted_bam='star/{sample}/Aligned.sortedByCoord.out.bam',
        chimeric_sam=temporary('star/{sample}/Chimeric.out.sam'),
        chimeric_junction=temporary('star/{sample}/Chimeric.out.junction'),
        quant_tx_bam='star/{sample}/Aligned.toTranscriptome.out.bam',
        quant_gene_count_tab=temporary('star/{sample}/ReadsPerGene.out.tab'),
        sj_count_tab=temporary('star/{sample}/SJ.out.tab'),
    input: unpack(find_sample_fastqs)
    params:
        star_ix=STAR_INDEX_FOLDER,
        out_folder='/star/{sample}/',
        outSAMattrRGline=create_rg_line
    log: 'logs/star/{sample}.log'
    threads: 8
    resources:
        io_heavy=1,
        mem_mb=lambda wildcards, attempt: 40000 + 8000 * (attempt - 1),
        tmp_mb=32000
    shell:
        "STAR "
        "--readFilesIn {input.r1_fq} {input.r2_fq} "
        # Most parameters follow GDC
        "--alignIntronMax 1000000 "
        "--alignIntronMin 20 "
        "--alignMatesGapMax 1000000 "
        "--alignSJDBoverhangMin 1 "
        "--alignSJoverhangMin 8 "
        "--alignSoftClipAtReferenceEnds Yes "

        # Follow arriba's recommendation regarding chimera parameters
        # Ref: https://arriba.readthedocs.io/en/latest/workflow/
        "--chimJunctionOverhangMin 10 "
        "--chimMainSegmentMultNmax 1 "
        "--chimOutType Junctions SeparateSAMold WithinBAM SoftClip "
        "--chimOutJunctionFormat 1 "
        "--chimSegmentMin 10 "
        "--chimScoreMin 1"
        "--chimScoreDropMax 30 "
        "--chimScoreJunctionNonGTAG 0 "
        "--chimScoreSeparation 1 "
        "--alignSJstitchMismatchNmax 5 -1 5 5 "
        "--chimSegmentReadGapMax 3 "

        "--genomeDir {params.star_ix} "
        "--genomeLoad NoSharedMemory "
        "--limitBAMsortRAM 0 "
        "--limitSjdbInsertNsj 1200000 "
        "--outFileNamePrefix {params.out_folder} "
        "--outFilterIntronMotifs None "
        "--outFilterMatchNminOverLread 0.33 "
        "--outFilterMismatchNmax 999 "
        "--outFilterMismatchNoverLmax 0.1 "
        "--outFilterMultimapNmax 20 "
        "--outFilterScoreMinOverLread 0.33 "
        "--outFilterType BySJout "
        "--outSAMattributes NH HI AS nM NM ch "
        "--outSAMattrRGline {params.outSAMattrRGline} "
        "--outSAMstrandField intronMotif "
        "--outSAMtype BAM Unsorted "
        "--outSAMunmapped Within "
        "--quantMode TranscriptomeSAM GeneCounts "
        "--readFilesCommand zcat "
        "--runThreadN {threads} "
        "--twopassMode Basic "
        "--outTmpDir $(mktemp -d)/_STARtmp "
        "> {log}"


rule samtools_index_bam:
    """Index a sorted BAM by samtools."""
    output: '{name}.bam.bai'
    input: '{name}.bam'
    resources:
        io_heavy=1
    shell: 'samtools index {input} {output}'


rule samtools_sort_star_bam:
    output: 'star/{sample}/Aligned.sortedByCoord.out.bam'
    input: rules.star_align.output.unsorted_bam
    threads: 8
    resources:
        io_heavy=1,
        mem_mb=lambda wildcards, attempt: 32000 + 8000 * (attempt - 1),
        tmp_mb=50000
    shell:
        "samtools sort "
        "--threads {threads} "
        # it uses much more memory than what's specified below
        "-m 1400M "
        "-T $(mktemp -d) "
        "-o {output} {input}"


rule samtools_sort_star_chimeric_bam:
    output: 'star/{sample}/Chimeric.out.sorted.bam'
    input: rules.star_align.output.chimeric_sam
    threads: 4
    resources:
        io_heavy=1,
        mem_mb=lambda wildcards, attempt: 4000 + 8000 * (attempt - 1),
        tmp_mb=8000
    shell:
        "samtools sort "
        "--threads {threads} -m 1400M "
        "-T $(mktemp -d) "
        "-o {output} {input}"


rule gzip_star_quant_tab:
    output: 'star/{sample}/ReadsPerGene.out.tab.gz'
    input: rules.star_align.output.quant_gene_count_tab
    shell: "gzip -9n -c {input} > {output}"


rule gzip_star_sj_tab:
    output: 'star/{sample}/SJ.pass1.out.tab.gz'
    input: rules.star_align.output.sj_count_tab
    shell: "gzip -9n -c {input} > {output}"


rule gzip_star_chimeric_junction:
    output: 'star/{sample}/Chimeric.out.junction.gz'
    input: rules.star_align.output.chimeric_junction
    shell: "gzip -9n -c {input} > {output}"



rule star_align_all_samples:
    """Align all RNA-seq samples."""
    input:
        all_genomic_bams=expand(rules.samtools_sort_star_bam.output[0], sample=SAMPLES),
        all_genomic_bais=expand(rules.samtools_sort_star_bam.output[0] + '.bai', sample=SAMPLES),
        all_chimeric_bams=expand(rules.samtools_sort_star_chimeric_bam.output[0], sample=SAMPLES),
        all_chimeric_bais=expand(rules.samtools_sort_star_chimeric_bam.output[0] + '.bai', sample=SAMPLES),
        all_quant_tx_bams=expand(rules.star_align.output.quant_tx_bam, sample=SAMPLES),
        all_quant_tabs=expand(rules.gzip_star_quant_tab.output, sample=SAMPLES),
        all_sj_tabs=expand(rules.gzip_star_sj_tab.output, sample=SAMPLES),
        all_sj_chimeric_junctions=expand(rules.gzip_star_chimeric_junction.output, sample=SAMPLES)


def gen_bam_map(bam_pth_pattern):
    """Generate the BAM map given the BAM file path pattern."""
    # Generate BAM map
    # (case, sample_type) -> bam_pth
    bam_map = {}
    for sample in SAMPLES:
        case, sample_type = sample.split('_', 1)
        bam_map[(case, sample_type)] = Path(bam_pth_pattern.format(sample=sample))
    return bam_map


def write_manifest(bam_map, manifest_pth):
    """Output the BAM map to the given manifest path."""
    columns = [
        '# sample_name', 'case', 'disease', 'experimental_strategy', 'sample_type',
        'data_path', 'filesize', 'data_format', 'reference', 'UUID', 'system'
    ]
    with open(manifest_pth, 'w') as f:
        writer = csv.writer(f, dialect='excel-tab', lineterminator='\n')
        writer.writerow(columns)  # Write header
        for (case, sample_type), data_pth in bam_map.items():
            if sample_type == 'blood_normal':
                abbrv = 'N'
            elif sample_type == 'tissue_normal':
                abbrv = 'A'
            elif sample_type == 'tumor':
                abbrv = 'T'
            else:
                raise ValueError(f'Unknown sample type {sample_type}')
            sample_name = f'{case}.RNA-Seq.{abbrv}.hg38-washu'
            file_size = data_pth.stat().st_size

            # Generate a new UUID
            data_id = str(uuid.uuid4())

            writer.writerow([
                sample_name, case, 'GBM', 'RNA-Seq', sample_type,
                str(data_pth), str(file_size), 'BAM', 'hg38', data_id, 'katmai',
            ])



rule gen_washu_bam_map:
    """Generate the map of the custom aligned BAMs."""
    output:
        unsorted_bam_map='tracked_results/washu_rnaseq_unsorted_bam_map.katmai.tsv',
        sorted_bam_map='tracked_results/washu_rnaseq_sorted_bam_map.katmai.tsv'
    input:
        all_genomic_bams=expand(rules.samtools_sort_star_bam.output[0], sample=SAMPLES),
        all_genomic_bais=expand(rules.samtools_sort_star_bam.output[0] + '.bai', sample=SAMPLES),
        all_chimeric_bams=expand(rules.samtools_sort_star_chimeric_bam.output[0], sample=SAMPLES),
        all_chimeric_bais=expand(rules.samtools_sort_star_chimeric_bam.output[0] + '.bai', sample=SAMPLES),
        all_quant_tx_bams=expand(rules.star_align.output.quant_tx_bam, sample=SAMPLES),
        all_quant_tabs=expand(rules.gzip_star_quant_tab.output, sample=SAMPLES),
        all_sj_tabs=expand(rules.gzip_star_sj_tab.output, sample=SAMPLES),
        all_sj_chimeric_junctions=expand(rules.gzip_star_chimeric_junction.output, sample=SAMPLES)
    run:
        for bam_pattern, manifest_pth in [
                (rules.star_align.output.unsorted_bam, output.unsorted_bam_map),
                (rules.star_align.output.sorted_bam, output.sorted_bam_map),
        ]:
            bam_map = gen_bam_map(bam_pattern)
            write_manifest(bam_map, manifest_pth)

